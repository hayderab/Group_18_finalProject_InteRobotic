
from helper import *








def Q(s, a):
    """
    Input sate, action
    Return optimal policy
    """
    pass

def P(s, a):
    """
    Inputs State and Action
    return porobality of ending up in the new state
    """
    pass

def policyIteration(S, A, P, R):
    """
    Inputs:
       S is the set of all states
       A is the set of all actions
       P is state transition function specifying P(s′∣s,a)
       R is a reward function R(s,a) 
    Return:
        Optimal policy pi       
    """
    # actionAarray = [a for a in S]
    # isChange = False
    # V = [s for s in S]
    
    # policy = [ ] 

    # while True:
    #     isChange = True
    #     V[s] = R(S,A) + gamma * sum()
    #     for  s in S:
    #         QBest = V[s]
    #         for a in A:
    #             pass
                
    #     if isChange == True:
    #         break  

    # return policy  
    pass